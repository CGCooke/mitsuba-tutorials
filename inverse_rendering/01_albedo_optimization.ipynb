{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Albedo optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this tutorial, we will build a simple example application that showcases differentiation and optimization of a light transport simulation involving the well-known Cornell Box scene. We are going to optimize the color of one of the walls of the Cornell Box to match a target image.\n",
    "\n",
    "Mitsuba’s ability to automatically differentiate entire rendering algorithms builds on differentiable JIT array types provided by the Enoki library. Those are explained in the [Enoki documentation](...). The linked document also discusses key differences compared to superficially similar frameworks like PyTorch and TensorFlow. For *automatic differentiation* (AD), Enoki records and simplifies computation graphs and uses them to propagate derivatives in forward or reverse mode. Before getting further into this tutorial, we recommend that you familiarize yourself this document.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "✔️ **What will you learn?**\n",
    "    \n",
    "<ul>\n",
    "  <li>Passing scene arguments when loading an XML file</li>\n",
    "  <li>Build an optimization pipeline using the optimizer classes</li>\n",
    "  <li>Perform gradient-based optimization using automatic differentiation</li>\n",
    "</ul>\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - setup\n",
    "\n",
    "In order to use the automatic differentiation, we need to enable a variant that supports it. Those are the ones containing `_ad` after the backend description. E.g. `cuda_ad_rgb`, `llvm_ad_rgb`, ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T13:34:32.362189Z",
     "start_time": "2021-06-15T13:34:32.351620Z"
    },
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# Add mitsuba and enoki to PATH (this shouldn't be necessary)\n",
    "import sys\n",
    "sys.path.append('../../../build/python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T14:13:40.427650Z",
     "start_time": "2021-06-15T14:13:40.259649Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import enoki as ek \n",
    "import mitsuba\n",
    "mitsuba.set_variant('cuda_ad_rgb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to pass arguments directly to the scene via the `load_file` rountine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T14:13:40.914750Z",
     "start_time": "2021-06-15T14:13:40.807334Z"
    }
   },
   "outputs": [],
   "source": [
    "from mitsuba.core.xml import load_file\n",
    "from mitsuba.python.util import traverse\n",
    "\n",
    "# TODO would be great no to have to do this!\n",
    "ek.set_flag(ek.JitFlag.LoopRecord,  False)\n",
    "\n",
    "scene = load_file('../scenes/cbox.xml', res=128, max_depth=3)\n",
    "params = traverse(scene)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we enabled a differentiable variant, when printing `params` you will notice the asterisk (`*`) on the left of some parameters which indicates that they are differentiable.\n",
    "\n",
    "``` python\n",
    "print(params)\n",
    "\n",
    "# Output\n",
    "SceneParameters[\n",
    "    ...\n",
    "    redwall.to_world,\n",
    "  * redwall.bsdf.reflectance.value,\n",
    "    redwall.vertex_count,\n",
    "    redwall.face_count,\n",
    "    redwall.faces,\n",
    "  * redwall.vertex_positions,\n",
    "  * redwall.vertex_normals,\n",
    "  * redwall.vertex_texcoords,\n",
    "    ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - reference image\n",
    "\n",
    "Our first experiment is going to be very simple: we will change the color of the red wall and then try to recover the original color using differentiation along with the reference image generated above. \n",
    "\n",
    "Before starting the optimization process, let's generate a reference image that will be used by the objective function. In contrast to the previous tutorial using `mitsuba.python.util.render` to render images, the differentiable rendering pipeline  involves another rendering function `mitsuba.python.autodiff.render` that is more optimized for this use case as it directly returns a JIT array containing the generated image. As we will soon discover, this function also takes arguments related to differential rendering.\n",
    "\n",
    "The `mitsuba.python.autodiff` submodule also provides a helper function to reshapes the output into an image of the correct size and exports it to any of the supported image formats (OpenEXR, PNG, JPG, RGBE, PFM) while automatically performing format conversion and gamma correction in the case of an 8-bit output format. The `write_async` argument can be used to performed this task asynchronously which is really handy when one wants to write images during the optimization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T14:13:48.087395Z",
     "start_time": "2021-06-15T14:13:47.195063Z"
    }
   },
   "outputs": [],
   "source": [
    "from mitsuba.python.util import write_bitmap, convert_to_bitmap\n",
    "\n",
    "integrator = scene.integrator()\n",
    "image_ref = integrator.render(scene, seed=0, spp=8)\n",
    "\n",
    "crop_size = scene.sensors()[0].film().crop_size()\n",
    "write_bitmap('out_ref.png', image_ref, crop_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to convert the data iamge to a `mitsuba.core.Bitmap` object and display it using `matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T14:13:48.974470Z",
     "start_time": "2021-06-15T14:13:48.773087Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_image(img, title):\n",
    "    plt.imshow(convert_to_bitmap(img, crop_size)); plt.axis('off'); plt.title(title);\n",
    "    plt.show()\n",
    "    \n",
    "show_image(image_ref, 'Reference image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s make a backup copy of this color value for later use and set it's value to a blue-ish color. As always, it is important not to forget to call `params.update()` to inform changed scene objects that they should refresh their internal state. \n",
    "\n",
    "This will be our initial state for the optimization process, which we can render and display to attest the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T14:13:50.155323Z",
     "start_time": "2021-06-15T14:13:49.440581Z"
    }
   },
   "outputs": [],
   "source": [
    "from mitsuba.core import Color3f\n",
    "\n",
    "key = 'redwall.bsdf.reflectance.value'\n",
    "\n",
    "params.keep([key])\n",
    "param_ref = Color3f(params[key])\n",
    "\n",
    "params[key] = Color3f(0.01, 0.2, 0.9)\n",
    "params.update()\n",
    "\n",
    "image_init = integrator.render(scene, seed=0, spp=8)\n",
    "show_image(image_init, 'Initial image')\n",
    "write_bitmap('out_init.png', image_init, crop_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO talk about `Optimizer`...\n",
    "\n",
    "In most cases, we will only be interested in differentiating a small subset of the (typically very large) parameters in the scene graph. It is responsability of the user to specify which parameters should be optimized and this can be done using the `load` method, which support list of keys and regular expressions as input argument to specify more than one parameter at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T14:13:51.368393Z",
     "start_time": "2021-06-15T14:13:51.362695Z"
    }
   },
   "outputs": [],
   "source": [
    "from mitsuba.core import Thread, LogLevel\n",
    "from mitsuba.python.ad.optimizers import Adam\n",
    "\n",
    "opt = Adam(lr=0.05, params=params)\n",
    "opt.load(key)\n",
    "opt.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T14:14:04.664564Z",
     "start_time": "2021-06-15T14:13:54.209445Z"
    }
   },
   "outputs": [],
   "source": [
    "Thread.thread().logger().set_log_level(LogLevel.Warn)\n",
    "\n",
    "errors = []\n",
    "for it in range(50):    \n",
    "    scene.sensors()[0].sampler().seed(0)\n",
    "    # Perform a differentiable rendering of the scene\n",
    "    # TODO: render separately to do unbiased=True\n",
    "    image = integrator.render(scene, seed=it, spp=1)\n",
    "\n",
    "    #write_bitmap('out_%03i.png' % it, image, crop_size)\n",
    "    \n",
    "    # Objective: MSE between 'image' and 'image_ref'\n",
    "    ob_val = ek.hsum_async(ek.sqr(image - image_ref)) / len(image)\n",
    "\n",
    "    # Back-propagate errors to input parameters\n",
    "    ek.backward(ob_val)\n",
    "\n",
    "    # Optimizer: take a gradient step\n",
    "    opt.step()\n",
    "    \n",
    "    opt[key] = ek.clamp(opt[key], 0.0, 1.0)\n",
    "    \n",
    "    # Optimizer: Update the scene parameters\n",
    "    opt.update()\n",
    "        \n",
    "    err_ref = ek.hsum(ek.sqr(param_ref - params[key]))\n",
    "    print('Iteration %03i: error=%g' % (it, err_ref[0]))\n",
    "    errors.append(err_ref)\n",
    "    \n",
    "print('Optimization complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T14:14:07.765382Z",
     "start_time": "2021-06-15T14:14:06.895491Z"
    }
   },
   "outputs": [],
   "source": [
    "image_final = integrator.render(scene, seed=0, spp=8)\n",
    "show_image(image_final, 'Final image')\n",
    "write_bitmap('out_final.png', image_final, crop_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T14:14:07.846488Z",
     "start_time": "2021-06-15T14:14:07.766615Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(errors)\n",
    "plt.xlabel('iteration'); plt.ylabel('MSE'); plt.title('Error plot');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Reference API*\n",
    "\n",
    "- [<code>mitsuba.core.xml.load_file</code>](https://mitsuba2.readthedocs.io/en/latest/generated/core_api.html#mitsuba.core.xml.load_file)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
